import streamlit as st
import cv2
import numpy as np
import av
from streamlit_webrtc import webrtc_streamer, VideoProcessorBase

# --- UIè¨­å®š ---
st.set_page_config(page_title="ç©¿åˆºã‚¬ã‚¤ãƒ‰ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿", layout="wide")
st.title("ğŸ’‰ ç©¿åˆºã‚¬ã‚¤ãƒ‰ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ (mmæŒ‡å®šç‰ˆ)")

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š ---

# 1. ã‚«ãƒ¡ãƒ©åˆ‡ã‚Šæ›¿ãˆ
st.sidebar.header("ğŸ“· ã‚«ãƒ¡ãƒ©è¨­å®š")
camera_mode = st.sidebar.radio(
    "ã‚«ãƒ¡ãƒ©ã®å‘ã",
    ("ã‚¤ãƒ³ã‚«ãƒ¡ãƒ© (è‡ªåˆ†å´)", "ã‚¢ã‚¦ãƒˆã‚«ãƒ¡ãƒ© (å¤–å´)"),
    index=1
)

if camera_mode == "ã‚¤ãƒ³ã‚«ãƒ¡ãƒ© (è‡ªåˆ†å´)":
    video_constraints = {"facingMode": "user", "width": {"ideal": 640}, "height": {"ideal": 480}}
else:
    video_constraints = {"facingMode": "environment", "width": {"ideal": 640}, "height": {"ideal": 480}}

# 2. ã‚¬ã‚¤ãƒ‰æ©Ÿèƒ½
st.sidebar.markdown("---")
st.sidebar.header("ğŸ“ ã‚¬ã‚¤ãƒ‰è¨­å®š")
show_guide = st.sidebar.checkbox("ç–‘ä¼¼é‡ï¼ˆã‚¬ã‚¤ãƒ‰ç·šï¼‰ã‚’è¡¨ç¤º", value=True)

# é•·ã•ã‚’ 1mm ï½ 5mm ã«å¤‰æ›´
# step=0.5 ã«ã—ã¦ã„ã‚‹ã®ã§ã€1.0, 1.5, ... 5.0mm ã¾ã§èª¿æ•´å¯èƒ½ã§ã™
guide_length_mm = st.sidebar.slider("ç–‘ä¼¼é‡ã®é•·ã• (mm)", 1.0, 5.0, 3.0, step=0.5)

# 3. èª¿æ•´ç”¨
st.sidebar.markdown("---")
st.sidebar.subheader("ğŸ‘€ èª¿æ•´")
show_edge = st.sidebar.checkbox("ã‚¨ãƒƒã‚¸ã®ã¿è¡¨ç¤º (èªè­˜ç¢ºèª)", value=False)


# --- Logic: æ˜ åƒå‡¦ç†ã‚¯ãƒ©ã‚¹ ---
class NeedleGuideSimulator(VideoProcessorBase):
    def __init__(self):
        self.show_guide = True
        self.guide_len_mm = 3.0
        self.debug_mode = False
        
        # ã€é‡è¦ã€‘1mmãŒä½•ãƒ”ã‚¯ã‚»ãƒ«ã‹ï¼Ÿã®å®šç¾©
        # ã‚«ãƒ¡ãƒ©ã®è·é›¢ã«ã‚ˆã‚Šã¾ã™ãŒã€æ¥å†™(ãƒã‚¯ãƒ­)ã¨ä»®å®šã—ã¦å¤§ãã‚ã«è¨­å®šã—ã¾ã™
        self.PX_PER_MM = 20.0 

    def update_settings(self, guide_on, guide_len_mm, debug):
        self.show_guide = guide_on
        self.guide_len_mm = guide_len_mm
        self.debug_mode = debug

    def recv(self, frame):
        try:
            img = frame.to_ndarray(format="bgr24")
            
            # 1. é‡ã®æ¤œå‡ºå‡¦ç†
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            blurred = cv2.GaussianBlur(gray, (5, 5), 0)
            edges = cv2.Canny(blurred, 50, 150)
            
            # ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰
            if self.debug_mode:
                return av.VideoFrame.from_ndarray(cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR), format="bgr24")

            lines = cv2.HoughLinesP(edges, 1, np.pi/180, threshold=50, minLineLength=60, maxLineGap=20)

            if lines is not None:
                best_line = None
                max_len = 0
                current_angle = 0.0
                
                # æœ€ã‚‚ç¢ºã‹ã‚‰ã—ã„é‡ã‚’æ¢ã™
                for line in lines:
                    lx1, ly1, lx2, ly2 = line[0]
                    if lx2 - lx1 == 0: la = 90.0
                    else: la = np.degrees(np.arctan2(abs(ly2 - ly1), abs(lx2 - lx1)))
                    
                    if 10 < la < 85:
                        length = np.sqrt((lx2 - lx1)**2 + (ly2 - ly1)**2)
                        if length > max_len:
                            max_len = length
                            best_line = line
                            current_angle = la
                
                # æç”»å‡¦ç†
                if best_line is not None:
                    bx1, by1, bx2, by2 = best_line[0]
                    # å…ˆç«¯(Yåº§æ¨™ãŒå¤§ãã„æ–¹ï¼ä¸‹)ã‚’ç‰¹å®š
                    if by1 > by2: 
                        tip = (bx1, by1); tail = (bx2, by2)
                    else: 
                        tip = (bx2, by2); tail = (bx1, by1)
                    
                    status_color = (0, 255, 255) # é»„
                    if 20 <= current_angle <= 40:
                        status_color = (255, 100, 0) # é’
                    
                    # é‡æœ¬ä½“
                    cv2.line(img, tail, tip, status_color, 6)
                    
                    # --- ç–‘ä¼¼é‡ï¼ˆmmæŒ‡å®šï¼‰ã®æç”» ---
                    if self.show_guide:
                        vec_x = tip[0] - tail[0]
                        vec_y = tip[1] - tail[1]
                        vec_len = np.sqrt(vec_x**2 + vec_y**2)
                        
                        if vec_len > 0:
                            unit_x = vec_x / vec_len
                            unit_y = vec_y / vec_len
                            
                            # mm ã‚’ px ã«å¤‰æ›ã—ã¦é•·ã•ã‚’æ±ºå®š
                            pixel_length = self.guide_len_mm * self.PX_PER_MM
                            
                            guide_end_x = int(tip[0] + unit_x * pixel_length)
                            guide_end_y = int(tip[1] + unit_y * pixel_length)
                            
                            # ã‚¬ã‚¤ãƒ‰ç·šï¼ˆæ°´è‰²ï¼‰
                            cv2.line(img, tip, (guide_end_x, guide_end_y), (255, 255, 0), 3)
                            # å…ˆç«¯ã«å°ã•ãªç‚¹
                            cv2.circle(img, (guide_end_x, guide_end_y), 3, (255, 255, 0), -1)

                    # ãƒ†ã‚­ã‚¹ãƒˆ
                    msg = f"Angle: {current_angle:.1f}"
                    cv2.putText(img, msg, (tail[0], tail[1]-20), cv2.FONT_HERSHEY_SIMPLEX, 1, status_color, 2)

            return av.VideoFrame.from_ndarray(img, format="bgr24")

        except Exception as e:
            err_img = frame.to_ndarray(format="bgr24")
            cv2.putText(err_img, f"Error: {e}", (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)
            return av.VideoFrame.from_ndarray(err_img, format="bgr24")

# --- ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œéƒ¨ ---
ctx = webrtc_streamer(
    key="needle-mm-guide",
    video_processor_factory=NeedleGuideSimulator,
    rtc_configuration={"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]},
    media_stream_constraints={"video": video_constraints, "audio": False}
)

if ctx.video_processor:
    ctx.video_processor.update_settings(show_guide, guide_length_mm, show_edge)
