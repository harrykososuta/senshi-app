import streamlit as st
import cv2
import numpy as np
import av
from streamlit_webrtc import webrtc_streamer, VideoProcessorBase

# --- UIè¨­å®š ---
st.set_page_config(page_title="ç©¿åˆºã‚¬ã‚¤ãƒ‰ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿", layout="wide")
st.title("ğŸ’‰ ç©¿åˆºã‚¬ã‚¤ãƒ‰ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ (ã‚¬ã‚¤ãƒ‰ç·šæ©Ÿèƒ½ä»˜)")

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š ---

# 1. ã‚«ãƒ¡ãƒ©åˆ‡ã‚Šæ›¿ãˆ
st.sidebar.header("ğŸ“· ã‚«ãƒ¡ãƒ©è¨­å®š")
camera_mode = st.sidebar.radio(
    "ã‚«ãƒ¡ãƒ©ã®å‘ã",
    ("ã‚¤ãƒ³ã‚«ãƒ¡ãƒ© (è‡ªåˆ†å´)", "ã‚¢ã‚¦ãƒˆã‚«ãƒ¡ãƒ© (å¤–å´)"),
    index=1
)

if camera_mode == "ã‚¤ãƒ³ã‚«ãƒ¡ãƒ© (è‡ªåˆ†å´)":
    video_constraints = {"facingMode": "user", "width": {"ideal": 640}, "height": {"ideal": 480}}
else:
    video_constraints = {"facingMode": "environment", "width": {"ideal": 640}, "height": {"ideal": 480}}

# 2. ã‚¬ã‚¤ãƒ‰æ©Ÿèƒ½
st.sidebar.markdown("---")
st.sidebar.header("ğŸ“ ã‚¬ã‚¤ãƒ‰è¨­å®š")
show_guide = st.sidebar.checkbox("ç–‘ä¼¼é‡ï¼ˆã‚¬ã‚¤ãƒ‰ç·šï¼‰ã‚’è¡¨ç¤º", value=True, help="é‡ã®å»¶é•·ç·šã‚’è¡¨ç¤ºã—ã¦ã€åˆºå…¥ä½ç½®ã‚’äºˆæ¸¬ã—ã¾ã™")
guide_length = st.sidebar.slider("ã‚¬ã‚¤ãƒ‰ç·šã®é•·ã•", 100, 1000, 500, step=50)

# 3. èª¿æ•´ç”¨ï¼ˆèªè­˜ã•ã‚Œã«ãã„æ™‚ç”¨ï¼‰
st.sidebar.markdown("---")
st.sidebar.subheader("ğŸ‘€ èª¿æ•´")
show_edge = st.sidebar.checkbox("ã‚¨ãƒƒã‚¸ã®ã¿è¡¨ç¤º (èªè­˜ç¢ºèª)", value=False)


# --- Logic: æ˜ åƒå‡¦ç†ã‚¯ãƒ©ã‚¹ ---
class NeedleGuideSimulator(VideoProcessorBase):
    def __init__(self):
        self.show_guide = True
        self.guide_len = 500
        self.debug_mode = False

    def update_settings(self, guide_on, guide_len, debug):
        self.show_guide = guide_on
        self.guide_len = guide_len
        self.debug_mode = debug

    def recv(self, frame):
        try:
            img = frame.to_ndarray(format="bgr24")
            
            # 1. é‡ã®æ¤œå‡ºå‡¦ç†
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            blurred = cv2.GaussianBlur(gray, (5, 5), 0)
            edges = cv2.Canny(blurred, 50, 150)
            
            # ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ï¼šã‚¨ãƒƒã‚¸ã ã‘è¿”ã™
            if self.debug_mode:
                return av.VideoFrame.from_ndarray(cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR), format="bgr24")

            lines = cv2.HoughLinesP(edges, 1, np.pi/180, threshold=50, minLineLength=60, maxLineGap=20)

            if lines is not None:
                best_line = None
                max_len = 0
                current_angle = 0.0
                
                # æœ€ã‚‚ç¢ºã‹ã‚‰ã—ã„é‡ã‚’æ¢ã™
                for line in lines:
                    lx1, ly1, lx2, ly2 = line[0]
                    if lx2 - lx1 == 0: la = 90.0
                    else: la = np.degrees(np.arctan2(abs(ly2 - ly1), abs(lx2 - lx1)))
                    
                    # è§’åº¦ãƒ•ã‚£ãƒ«ã‚¿ (10åº¦ã€œ85åº¦)
                    if 10 < la < 85:
                        length = np.sqrt((lx2 - lx1)**2 + (ly2 - ly1)**2)
                        if length > max_len:
                            max_len = length
                            best_line = line
                            current_angle = la
                
                # é‡ãŒè¦‹ã¤ã‹ã£ãŸå ´åˆã®æç”»å‡¦ç†
                if best_line is not None:
                    bx1, by1, bx2, by2 = best_line[0]
                    # å…ˆç«¯(Yåº§æ¨™ãŒå¤§ãã„æ–¹ï¼ä¸‹)ã‚’ç‰¹å®š
                    if by1 > by2: 
                        tip = (bx1, by1)  # å…ˆç«¯
                        tail = (bx2, by2) # æ ¹å…ƒ
                    else: 
                        tip = (bx2, by2)
                        tail = (bx1, by1)
                    
                    # è§’åº¦ã«ã‚ˆã‚‹è‰²åˆ†ã‘
                    status_color = (0, 255, 255) # é»„ (æ³¨æ„)
                    if 20 <= current_angle <= 40:
                        status_color = (255, 100, 0) # é’ (è‰¯å¥½)
                    
                    # --- é‡æœ¬ä½“ã®æç”» ---
                    cv2.line(img, tail, tip, status_color, 6)
                    
                    # --- ç–‘ä¼¼é‡ï¼ˆã‚¬ã‚¤ãƒ‰ç·šï¼‰ã®æç”» ---
                    if self.show_guide:
                        # å˜ä½ãƒ™ã‚¯ãƒˆãƒ«ã‚’è¨ˆç®—
                        vec_x = tip[0] - tail[0]
                        vec_y = tip[1] - tail[1]
                        vec_len = np.sqrt(vec_x**2 + vec_y**2)
                        
                        if vec_len > 0:
                            unit_x = vec_x / vec_len
                            unit_y = vec_y / vec_len
                            
                            # ã‚¬ã‚¤ãƒ‰ã®çµ‚ç‚¹è¨ˆç®—
                            guide_end_x = int(tip[0] + unit_x * self.guide_len)
                            guide_end_y = int(tip[1] + unit_y * self.guide_len)
                            
                            # ã‚¬ã‚¤ãƒ‰ç·šã‚’æç”»ï¼ˆæ°´è‰²ï¼‰
                            cv2.line(img, tip, (guide_end_x, guide_end_y), (255, 255, 0), 2)
                            # å…ˆç«¯ã«ãƒãƒ¼ã‚¯
                            cv2.circle(img, tip, 5, (255, 255, 0), -1)

                    # ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±
                    msg = f"Angle: {current_angle:.1f}"
                    cv2.putText(img, msg, (tail[0], tail[1]-20), cv2.FONT_HERSHEY_SIMPLEX, 1, status_color, 2)

            return av.VideoFrame.from_ndarray(img, format="bgr24")

        except Exception as e:
            err_img = frame.to_ndarray(format="bgr24")
            cv2.putText(err_img, f"Error: {e}", (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)
            return av.VideoFrame.from_ndarray(err_img, format="bgr24")

# --- ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œéƒ¨ ---
ctx = webrtc_streamer(
    key="needle-guide-mode",
    video_processor_factory=NeedleGuideSimulator,
    rtc_configuration={"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]},
    media_stream_constraints={"video": video_constraints, "audio": False}
)

if ctx.video_processor:
    ctx.video_processor.update_settings(show_guide, guide_length, show_edge)
