import streamlit as st
import cv2
import numpy as np
import av
from streamlit_webrtc import webrtc_streamer, VideoProcessorBase, RTCConfiguration, WebRtcMode

# --- UIè¨­å®š ---
st.set_page_config(page_title="ç©¿åˆºã‚¬ã‚¤ãƒ‰ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿", layout="wide")
st.title("ğŸ’‰ ç©¿åˆºã‚¬ã‚¤ãƒ‰ - ãƒ•ã‚©ãƒ¼ã‚«ã‚¹ãƒ¢ãƒ¼ãƒ‰æ­è¼‰")
st.caption("Ver 4.0 - ROI Focus")

# --- é€šä¿¡è¨­å®š ---
# â€»ã“ã“ã«å‰å›ã® Metered.ca ã®è¨­å®šï¼ˆTURN_USERNAME, TURN_PASSWORDï¼‰ãŒã‚ã‚Œã°ãã®ã¾ã¾ä½¿ã£ã¦ãã ã•ã„
# ãªã‘ã‚Œã°Googleã®ç„¡æ–™ã‚µãƒ¼ãƒãƒ¼ã‚’ä½¿ã„ã¾ã™ï¼ˆWi-Fiæ¨å¥¨ï¼‰
RTC_CONFIGURATION = RTCConfiguration(
    {"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]}
)

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š ---
st.sidebar.header("ğŸ“· ã‚«ãƒ¡ãƒ©è¨­å®š")
camera_mode = st.sidebar.radio(
    "ã‚«ãƒ¡ãƒ©ã®å‘ã",
    ("ã‚¤ãƒ³ã‚«ãƒ¡ãƒ© (è‡ªåˆ†å´)", "ã‚¢ã‚¦ãƒˆã‚«ãƒ¡ãƒ© (å¤–å´)"),
    index=1
)

if camera_mode == "ã‚¤ãƒ³ã‚«ãƒ¡ãƒ© (è‡ªåˆ†å´)":
    video_constraints = {"facingMode": "user", "width": {"ideal": 640}, "height": {"ideal": 480}}
else:
    video_constraints = {"facingMode": "environment", "width": {"ideal": 640}, "height": {"ideal": 480}}

st.sidebar.markdown("---")
st.sidebar.header("ğŸ¯ èªè­˜ç¯„å›²ã®è¨­å®š")
st.sidebar.info("èƒŒæ™¯ã®èª¤æ¤œçŸ¥ã‚’é˜²ããŸã‚ã€èªè­˜ã™ã‚‹ç¯„å›²ã‚’çµã‚Šã¾ã™ã€‚")
roi_size = st.sidebar.slider("æ¤œå‡ºæ ã®ã‚µã‚¤ã‚º (%)", 10, 100, 50, help="å€¤ã‚’å°ã•ãã™ã‚‹ã¨ã€ç”»é¢ä¸­å¤®ã®ã¿ã‚’è§£æã—ã¾ã™")

st.sidebar.markdown("---")
st.sidebar.header("ğŸ“ ã‚¬ã‚¤ãƒ‰è¨­å®š")
show_guide = st.sidebar.checkbox("ç–‘ä¼¼é‡ï¼ˆã‚¬ã‚¤ãƒ‰ç·šï¼‰ã‚’è¡¨ç¤º", value=True)
guide_length_mm = st.sidebar.slider("ç–‘ä¼¼é‡ã®é•·ã• (mm)", 1.0, 5.0, 3.0, step=0.5)
show_debug = st.sidebar.checkbox("è§£æé ˜åŸŸã‚’ç¢ºèª (ãƒ‡ãƒãƒƒã‚°)", value=False)

# --- æ˜ åƒå‡¦ç†ã‚¯ãƒ©ã‚¹ ---
class NeedleGuideSimulator(VideoProcessorBase):
    def __init__(self):
        self.show_guide = True
        self.guide_len_mm = 3.0
        self.roi_percent = 50
        self.show_debug = False
        self.PX_PER_MM = 20.0 

    def update_settings(self, guide_on, guide_len_mm, roi, debug):
        self.show_guide = guide_on
        self.guide_len_mm = guide_len_mm
        self.roi_percent = roi
        self.show_debug = debug

    def recv(self, frame):
        try:
            img = frame.to_ndarray(format="bgr24")
            height, width = img.shape[:2]

            # --- 1. ROIï¼ˆæ³¨ç›®ã‚¨ãƒªã‚¢ï¼‰ã®è¨ˆç®— ---
            # ç”»é¢ä¸­å¤®ã‹ã‚‰æŒ‡å®šã•ã‚ŒãŸï¼…åˆ†ã®é ˜åŸŸã‚’è¨ˆç®—
            roi_w = int(width * (self.roi_percent / 100))
            roi_h = int(height * (self.roi_percent / 100))
            roi_x = int((width - roi_w) / 2)
            roi_y = int((height - roi_h) / 2)

            # --- 2. è§£æç”¨ã®ç”»åƒã‚’ä½œæˆ ---
            # ã¾ãšçœŸã£é»’ãªç”»åƒã‚’ä½œã‚‹
            mask = np.zeros_like(img)
            # æ³¨ç›®ã‚¨ãƒªã‚¢ã ã‘ç™½ã„å››è§’ã‚’æã
            cv2.rectangle(mask, (roi_x, roi_y), (roi_x + roi_w, roi_y + roi_h), (255, 255, 255), -1)
            
            # å…ƒç”»åƒã¨ãƒã‚¹ã‚¯ã‚’åˆæˆï¼ˆæ³¨ç›®ã‚¨ãƒªã‚¢ä»¥å¤–ã‚’é»’ãå¡—ã‚Šã¤ã¶ã—ãŸç”»åƒã‚’ä½œã‚‹ï¼‰
            masked_img = cv2.bitwise_and(img, mask)

            # --- 3. ç”»åƒå‡¦ç†ï¼ˆãƒã‚¹ã‚¯ã•ã‚ŒãŸç”»åƒã«å¯¾ã—ã¦è¡Œã†ï¼‰ ---
            gray = cv2.cvtColor(masked_img, cv2.COLOR_BGR2GRAY)
            blurred = cv2.GaussianBlur(gray, (5, 5), 0)
            edges = cv2.Canny(blurred, 50, 150)
            
            # ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰ï¼šèªè­˜ã—ã¦ã„ã‚‹ã‚¨ãƒƒã‚¸ã‚’è¡¨ç¤º
            if self.show_debug:
                # æ ã‚’æç”»ã—ã¦è¿”ã™
                cv2.rectangle(img, (roi_x, roi_y), (roi_x + roi_w, roi_y + roi_h), (0, 255, 0), 2)
                # ã‚¨ãƒƒã‚¸ç”»åƒã‚’ã‚«ãƒ©ãƒ¼å¤‰æ›ã—ã¦åˆæˆï¼ˆé€ã‹ã—ã¦è¦‹ã›ã‚‹ï¼‰
                edge_color = cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR)
                return av.VideoFrame.from_ndarray(cv2.addWeighted(img, 0.8, edge_color, 0.5, 0), format="bgr24")

            # ç›´ç·šæ¤œå‡º
            lines = cv2.HoughLinesP(edges, 1, np.pi/180, threshold=50, minLineLength=60, maxLineGap=20)
            
            best_line = None
            max_len = 0
            current_angle = 0.0
            
            if lines is not None:
                for line in lines:
                    lx1, ly1, lx2, ly2 = line[0]
                    
                    # è§’åº¦è¨ˆç®—
                    if lx2 - lx1 == 0: la = 90.0
                    else: la = np.degrees(np.arctan2(abs(ly2 - ly1), abs(lx2 - lx1)))
                    
                    # è§’åº¦ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆæ¥µç«¯ãªè§’åº¦ã¯é™¤å¤–ï¼‰
                    if 10 < la < 85:
                        length = np.sqrt((lx2 - lx1)**2 + (ly2 - ly1)**2)
                        if length > max_len:
                            max_len = length
                            best_line = line
                            current_angle = la
                
                # --- 4. æç”»ï¼ˆå…ƒã®ç¶ºéº—ãªç”»åƒã®ä¸Šã«æãï¼‰ ---
                if best_line is not None:
                    bx1, by1, bx2, by2 = best_line[0]
                    if by1 < by2: tip = (bx1, by1); tail = (bx2, by2)
                    else: tip = (bx2, by2); tail = (bx1, by1)
                    
                    status_color = (0, 255, 255)
                    if 20 <= current_angle <= 40: status_color = (0, 165, 255)
                    
                    # é‡ã®ç·š
                    cv2.line(img, tail, tip, status_color, 6)
                    
                    # ã‚¬ã‚¤ãƒ‰ç·š
                    if self.show_guide:
                        vec_x = tip[0] - tail[0]
                        vec_y = tip[1] - tail[1]
                        vec_len = np.sqrt(vec_x**2 + vec_y**2)
                        if vec_len > 0:
                            unit_x = vec_x / vec_len
                            unit_y = vec_y / vec_len
                            pixel_length = self.guide_len_mm * self.PX_PER_MM
                            guide_end_x = int(tip[0] + unit_x * pixel_length)
                            guide_end_y = int(tip[1] + unit_y * pixel_length)
                            cv2.line(img, tip, (guide_end_x, guide_end_y), (255, 255, 0), 3)
                            cv2.circle(img, (guide_end_x, guide_end_y), 5, (255, 255, 0), -1)

                    msg = f"Angle: {current_angle:.1f}"
                    cv2.putText(img, msg, (tail[0], tail[1]-20), cv2.FONT_HERSHEY_SIMPLEX, 1, status_color, 2)

            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¸ã®æ¡ˆå†…ç”¨ã«ã€èªè­˜ã‚¨ãƒªã‚¢ï¼ˆROIï¼‰ã®æ ã‚’è–„ãè¡¨ç¤ºã™ã‚‹
            cv2.rectangle(img, (roi_x, roi_y), (roi_x + roi_w, roi_y + roi_h), (0, 255, 0), 2)
            cv2.putText(img, "Target Area", (roi_x, roi_y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)

            return av.VideoFrame.from_ndarray(img, format="bgr24")
        except Exception as e:
            print(f"Error: {e}")
            return frame

# --- ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œéƒ¨ ---
ctx = webrtc_streamer(
    key="needle-roi-focus",
    mode=WebRtcMode.SENDRECV,
    rtc_configuration=RTC_CONFIGURATION,
    video_processor_factory=NeedleGuideSimulator,
    media_stream_constraints={"video": video_constraints, "audio": False},
    async_processing=True,
)

if ctx.video_processor:
    ctx.video_processor.update_settings(show_guide, guide_length_mm, roi_size, show_debug)
