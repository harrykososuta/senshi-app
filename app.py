import streamlit as st
import cv2
import numpy as np
import av
import pandas as pd
from streamlit_webrtc import webrtc_streamer, VideoProcessorBase, RTCConfiguration, WebRtcMode

# --- UIè¨­å®š ---
st.set_page_config(page_title="ç©¿åˆºã‚¬ã‚¤ãƒ‰ - å®Ÿè·µãƒ¢ãƒ¼ãƒ‰", layout="centered") # ã‚¹ãƒãƒ›ã§è¦‹ã‚„ã™ã„ã‚ˆã†centeredã«å¤‰æ›´
st.title("ğŸ’‰ ç©¿åˆºã‚¬ã‚¤ãƒ‰ - å®Ÿè·µãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰")

# --- é€šä¿¡è¨­å®š ---
TURN_USERNAME = "ã€ã“ã“ã«usernameã€‘"
TURN_PASSWORD = "ã€ã“ã“ã«passwordã€‘"

RTC_CONFIGURATION = RTCConfiguration(
    {
        "iceServers": [
            {"urls": ["stun:stun.l.google.com:19302"]},
            # Meteredè¨­å®šãŒã‚ã‚‹å ´åˆã¯ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆã‚’å¤–ã™
            # {
            #     "urls": ["turn:global.turn.metered.ca:80", "turn:global.turn.metered.ca:443"],
            #     "username": TURN_USERNAME,
            #     "credential": TURN_PASSWORD,
            # },
        ]
    }
)

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®šï¼ˆèª¿æ•´é …ç›®ã®ã¿ï¼‰ ---
st.sidebar.header("âš™ï¸ èª¿æ•´")
st.sidebar.subheader("ğŸ¥ èªè­˜è¨­å®š")
roi_size = st.sidebar.slider("æ¤œå‡ºæ ã‚µã‚¤ã‚º (%)", 10, 100, 40)
threshold = st.sidebar.slider("æ¤œå‡ºæ„Ÿåº¦", 30, 150, 50)
flip_tip = st.sidebar.checkbox("é‡å…ˆã®å‘ãã‚’åè»¢", value=False, help="ã‚¬ã‚¤ãƒ‰ç·šãŒé€†ã«å‡ºã‚‹å ´åˆã¯ãƒã‚§ãƒƒã‚¯ã—ã¦ãã ã•ã„")

st.sidebar.subheader("ğŸ§ª ãƒ†ã‚¹ãƒˆåŸºæº–")
target_angle = st.sidebar.number_input("ç›®æ¨™è§’åº¦ (åº¦)", 10.0, 60.0, 30.0, step=1.0)
guide_len_mm = st.sidebar.slider("ã‚¬ã‚¤ãƒ‰ç·šã®é•·ã• (mm)", 1.0, 10.0, 5.0, step=0.5)

# --- æ˜ åƒå‡¦ç†ã‚¯ãƒ©ã‚¹ ---
class NeedleGuideSimulator(VideoProcessorBase):
    def __init__(self):
        self.roi_percent = 40
        self.threshold = 50
        self.target_angle = 30.0
        self.flip_tip = False
        self.guide_len_mm = 5.0
        
        self.is_recording = False
        self.angle_history = []
        self.last_frame = None
        self.PX_PER_MM = 20.0 

    def update_settings(self, roi, thresh, target, flip, guide_len):
        self.roi_percent = roi
        self.threshold = thresh
        self.target_angle = target
        self.flip_tip = flip
        self.guide_len_mm = guide_len

    def start_test(self):
        self.angle_history = []
        self.is_recording = True

    def stop_test(self):
        self.is_recording = False
        return self.angle_history

    def get_last_frame(self):
        return self.last_frame

    def recv(self, frame):
        try:
            img = frame.to_ndarray(format="bgr24")
            height, width = img.shape[:2]
            
            # --- ROIè¨ˆç®— ---
            roi_w = int(width * (self.roi_percent / 100))
            roi_h = int(height * (self.roi_percent / 100))
            roi_x = int((width - roi_w) / 2)
            roi_y = int((height - roi_h) / 2)

            mask = np.zeros_like(img)
            cv2.rectangle(mask, (roi_x, roi_y), (roi_x + roi_w, roi_y + roi_h), (255, 255, 255), -1)
            masked_img = cv2.bitwise_and(img, mask)

            gray = cv2.cvtColor(masked_img, cv2.COLOR_BGR2GRAY)
            blurred = cv2.GaussianBlur(gray, (5, 5), 0)
            edges = cv2.Canny(blurred, 50, 150)
            lines = cv2.HoughLinesP(edges, 1, np.pi/180, threshold=self.threshold, minLineLength=60, maxLineGap=20)
            
            current_angle = None
            best_line = None
            max_len = 0
            
            if lines is not None:
                for line in lines:
                    lx1, ly1, lx2, ly2 = line[0]
                    if lx2 - lx1 == 0: la = 90.0
                    else: la = np.degrees(np.arctan2(abs(ly2 - ly1), abs(lx2 - lx1)))
                    
                    if 10 < la < 85:
                        length = np.sqrt((lx2 - lx1)**2 + (ly2 - ly1)**2)
                        if length > max_len:
                            max_len = length
                            best_line = line
                            current_angle = la

            # --- æç”» ---
            if best_line is not None:
                bx1, by1, bx2, by2 = best_line[0]
                
                # é‡å…ˆ(Tip)ã®åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯ä¿®æ­£
                # é€šå¸¸: YãŒå¤§ãã„æ–¹(ç”»é¢ä¸‹å´)ãŒTip
                if by1 > by2: # by1ã®æ–¹ãŒä¸‹ã«ã‚ã‚‹
                    tip = (bx1, by1); tail = (bx2, by2)
                else: # by2ã®æ–¹ãŒä¸‹ã«ã‚ã‚‹
                    tip = (bx2, by2); tail = (bx1, by1)
                
                # åè»¢è¨­å®šãŒã‚ã‚Œã°é€†ã«ã™ã‚‹
                if self.flip_tip:
                    tip, tail = tail, tip

                # è¨˜éŒ²ãƒ»ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹
                status_color = (0, 255, 255)
                if self.is_recording:
                    self.angle_history.append(current_angle)
                    status_color = (0, 0, 255)
                    cv2.circle(img, (30, 30), 15, (0, 0, 255), -1)

                if abs(current_angle - self.target_angle) < 5.0:
                    status_color = (0, 255, 0) # Good!

                # é‡æœ¬ä½“
                cv2.line(img, tail, tip, status_color, 6)
                
                # ã‚¬ã‚¤ãƒ‰ç·šï¼ˆTipã‹ã‚‰å»¶é•·ã™ã‚‹ï¼‰
                vec_x = tip[0] - tail[0]
                vec_y = tip[1] - tail[1]
                vec_len = np.sqrt(vec_x**2 + vec_y**2)
                
                if vec_len > 0:
                    unit_x = vec_x / vec_len
                    unit_y = vec_y / vec_len
                    pixel_len = self.guide_len_mm * self.PX_PER_MM
                    
                    guide_end_x = int(tip[0] + unit_x * pixel_len)
                    guide_end_y = int(tip[1] + unit_y * pixel_len)
                    
                    # ã‚¬ã‚¤ãƒ‰ç·š (é»„è‰²ã„ç‚¹ç·šã‚¤ãƒ¡ãƒ¼ã‚¸ã®å®Ÿç·š)
                    cv2.line(img, tip, (guide_end_x, guide_end_y), (255, 255, 0), 2)
                    cv2.circle(img, (guide_end_x, guide_end_y), 4, (255, 255, 0), -1)

                msg = f"{current_angle:.1f}"
                cv2.putText(img, msg, (tip[0] + 10, tip[1]), cv2.FONT_HERSHEY_SIMPLEX, 1, status_color, 2)

            # æ è¡¨ç¤º
            border_color = (0, 0, 255) if self.is_recording else (0, 255, 0)
            cv2.rectangle(img, (roi_x, roi_y), (roi_x + roi_w, roi_y + roi_h), border_color, 2)
            self.last_frame = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

            return av.VideoFrame.from_ndarray(img, format="bgr24")
        except:
            return frame

# --- ãƒ¡ã‚¤ãƒ³ç”»é¢ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ ---
# ã‚«ãƒ¡ãƒ©æ˜ åƒ
ctx = webrtc_streamer(
    key="needle-main",
    mode=WebRtcMode.SENDRECV,
    rtc_configuration=RTC_CONFIGURATION,
    video_processor_factory=NeedleGuideSimulator,
    media_stream_constraints={"video": {"facingMode": "environment"}, "audio": False},
    async_processing=True,
)

# --- ã“ã“ã«æ“ä½œãƒœã‚¿ãƒ³ã‚’é›†ç´„ï¼ˆãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢ï¼‰ ---
st.markdown("### ğŸ® æ“ä½œãƒ‘ãƒãƒ«")

# ProcessorãŒå‹•ã„ã¦ã„ã‚‹æ™‚ã ã‘è¡¨ç¤º
if ctx.video_processor:
    ctx.video_processor.update_settings(roi_size, threshold, target_angle, flip_tip, guide_len_mm)

    # ãƒœã‚¿ãƒ³ã‚’æ¨ªä¸¦ã³ã«ã™ã‚‹
    btn_col1, btn_col2, btn_col3 = st.columns(3)

    # 1. ãƒ†ã‚¹ãƒˆé–‹å§‹/çµ‚äº†ãƒœã‚¿ãƒ³
    if 'testing' not in st.session_state:
        st.session_state.testing = False

    with btn_col1:
        if not st.session_state.testing:
            if st.button("â–¶ï¸ ãƒ†ã‚¹ãƒˆé–‹å§‹", use_container_width=True, type="primary"):
                ctx.video_processor.start_test()
                st.session_state.testing = True
                st.rerun()
        else:
            if st.button("â¹ï¸ çµ‚äº†ãƒ»æ¡ç‚¹", use_container_width=True, type="primary"):
                history = ctx.video_processor.stop_test()
                st.session_state.testing = False
                st.session_state.test_result = history
                st.rerun()

    # 2. é™æ­¢ç”»ä¿å­˜ãƒœã‚¿ãƒ³
    with btn_col2:
        if st.button("ğŸ“· æ’®å½±", use_container_width=True):
            frame = ctx.video_processor.get_last_frame()
            if frame is not None:
                st.session_state.last_capture = frame
            else:
                st.toast("æ˜ åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

    # 3. ãƒªã‚»ãƒƒãƒˆãƒœã‚¿ãƒ³
    with btn_col3:
        if st.button("ğŸ”„ ãƒªã‚»ãƒƒãƒˆ", use_container_width=True):
            if 'test_result' in st.session_state:
                del st.session_state.test_result
            if 'last_capture' in st.session_state:
                del st.session_state.last_capture
            st.rerun()

else:
    st.info("ä¸Šã®ã€ŒSTARTã€ã‚’æŠ¼ã—ã¦ã‚«ãƒ¡ãƒ©ã‚’èµ·å‹•ã—ã¦ãã ã•ã„")

# --- çµæœãƒ»ç”»åƒè¡¨ç¤ºã‚¨ãƒªã‚¢ ---
st.markdown("---")

# ã‚­ãƒ£ãƒ—ãƒãƒ£ç”»åƒã®è¡¨ç¤º
if 'last_capture' in st.session_state:
    st.image(st.session_state.last_capture, caption="æ’®å½±ç”»åƒ", use_container_width=True)
    # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ç”¨
    is_success, buffer = cv2.imencode(".png", cv2.cvtColor(st.session_state.last_capture, cv2.COLOR_RGB2BGR))
    if is_success:
        st.download_button("ç”»åƒã‚’ä¿å­˜", buffer.tobytes(), "puncture.png", "image/png")

# ãƒ†ã‚¹ãƒˆçµæœã®è¡¨ç¤º
if 'test_result' in st.session_state and st.session_state.test_result:
    data = st.session_state.test_result
    if len(data) > 5:
        df = pd.DataFrame(data, columns=["Angle"])
        avg = df["Angle"].mean()
        std = df["Angle"].std()
        score = max(0, int(100 - abs(avg - target_angle)*2 - std*5))
        
        st.success(f"ğŸ† ã‚¹ã‚³ã‚¢: {score} ç‚¹")
        cols = st.columns(2)
        cols[0].metric("å¹³å‡è§’åº¦", f"{avg:.1f}Â°", f"{avg - target_angle:.1f}")
        cols[1].metric("å®‰å®šæ€§(Â±)", f"{std:.2f}")
        st.line_chart(df)
    else:
        st.warning("ãƒ‡ãƒ¼ã‚¿ãŒçŸ­ã™ãã¾ã™")
